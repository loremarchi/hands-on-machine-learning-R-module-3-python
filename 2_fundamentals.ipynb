{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Data sets in use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Data sets used in this course - MTPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will (once again) use the Motor Third Party Liability data set. There are 163,231 policyholders in this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequency of claiming ( nclaims ) and corresponding severity ( avg , the amount paid on average per claim reported by a\n",
    "policyholder) are the target variables in this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictor variables are:\n",
    "* the exposure-to-risk, the duration of the insurance coverage (max. 1 year)\n",
    "* factor variables, e.g. gender, coverage, fuel\n",
    "* continuous, numeric variables, e.g. age of the policyholder, age of the car\n",
    "* spatial information: postal code (in Belgium) of the municipality where the policyholder resides.  \n",
    "\n",
    "More details in [Henckaerts et al. (2018, Scandinavian Actuarial Journal)](https://katrienantonio.github.io/projects/2019/06/13/machine-learning/#data-driven) and [Henckaerts et al. (2019, arxiv)](https://katrienantonio.github.io/projects/2019/06/13/machine-learning/#tree-based-pricing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Data sets used in this course - MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed, not all data are in tabular format. We analyze an image database from the Modified National Institute of Standards and Technology, short MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with MNIST will learn us how machine learning methods can be used to work with new data sources, such as images.\n",
    "* Large database of 70,000 labeled images of\n",
    "handwritten digits, see\n",
    "http://yann.lecun.com/exdb/mnist/\n",
    "* Images are preprocessed, i.e. scaled and centered.\n",
    "* Classic test case for machine learning classification\n",
    "algorithms. Current models achieve an accuracy of\n",
    "[more than 99.5%](https://en.wikipedia.org/wiki/MNIST_database).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are in grayscale. Each image is stored as a 28x28 intensity matrix, with intensity expressed on a scale from 0-255.\n",
    "<img src=\"./imgs/mnist_1.png\" width=\"300\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recognizing that the images below all represent the digit 8 is trivial for humans, but difficult for computers.\n",
    "<img src=\"./imgs/mnist_2.png\" width=\"350\" height=\"350\" align=\"center\"/>\n",
    "Neural networks are ideal for situations where the relation between the input (here: intensity matrix) and the output (here: 0-9) is complicated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "seed = 123\n",
    "\n",
    "def reset_random_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "reset_random_seeds(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mnist data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:(60000, 28, 28), y_train:(60000,), x_test:(10000, 28, 28), y_test:(10000,)\n"
     ]
    }
   ],
   "source": [
    "# validate dimension\n",
    "print(f'x_train:{x_train.shape}, y_train:{y_train.shape}, x_test:{x_test.shape}, y_test:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop at the first matrix \"in the dimension depth\"\n",
    "x_train[0,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image data (28x28) is flattened into a vector of length 784:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape x_train(flatten the tensor as ANN takes vector data as input)\n",
    "vec_x_train = tf.reshape(x_train, shape = [x_train.shape[0], x_train.shape[1]*x_train.shape[1]])\n",
    "proto_tensor = tf.make_tensor_proto(vec_x_train)\n",
    "arr_vec_x_train = tf.make_ndarray(proto_tensor)/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following matrix, each row corresponds to one (flattened) image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2, shape=(60000, 784), dtype=uint8, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_x_train #tf.Tensor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_vec_x_train #np.array object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min:0.0, max:1.0\n"
     ]
    }
   ],
   "source": [
    "# Image values in train_x vector have been normalized\n",
    "print(f'min:{np.min(arr_vec_x_train)}, max:{np.max(arr_vec_x_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape x_test(flatten the tensor as ANN takes vector data as input)\n",
    "vec_x_test = tf.reshape(x_test, shape = [x_test.shape[0],x_test.shape[1]*x_test.shape[1]])\n",
    "proto_tensor = tf.make_tensor_proto(vec_x_test)\n",
    "arr_vec_x_test = tf.make_ndarray(proto_tensor)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5, shape=(10000, 784), dtype=uint8, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_x_test #tf.Tensor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_vec_x_test #np.array object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min:0.0, max:1.0\n"
     ]
    }
   ],
   "source": [
    "# image values in test_x vector have been normalized:\n",
    "print(f'min:{np.min(arr_vec_x_test)}, max:{np.max(arr_vec_x_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We point out that we are dealing with a multi-class classification problem - elements must be classified in 10 categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique y_train:[0 1 2 3 4 5 6 7 8 9], unique y_test:[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Unique elements in y_train and y_test vectors\n",
    "print(f'unique y_train:{np.unique(y_train)}, unique y_test:{np.unique(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct 10 dummy variables (0-9) for the output of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train\n",
    "output = tf.keras.utils.to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test\n",
    "test_output = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of output:(60000, 10), shape of test_output:(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# let's highlight the shape of the newly created np.array objects\n",
    "print(f'shape of output:{output.shape}, shape of test_output:{test_output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract one row from the matrix arr_vec_x_train, we reshape it to (28x28) pixel format so that we can easily print it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 16\n",
    "pixels = arr_vec_x_train[index].reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 De-mystifying neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different types of neural networks and their applications:\n",
    "* ANN: Artificial Neural Network for regression and classification problems, with vectors as input data\n",
    "* CNN: Convolutional Neural Network for image processing, image/face/... recognition, with images as input data\n",
    "* RNN: Recurrent Neural Network for sequential data such as text or time series\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De-mystify artificial neural networks (ANNs):\n",
    "* a collection of inter-woven linear models\n",
    "* extending linear approaches to detect non-linear interactions in high-dimensional data.\n",
    "<img src=\"./imgs/nn_1.png\" width=\"300\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "Some terminology:\n",
    "* $x$ is the input layer\n",
    "* $v$ is the output layer middle layer is a hidden layer\n",
    "* four neurons: $x, z_{1}, z_{2}$ and $v$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we apply two independent linear models:\n",
    "$$\n",
    "\\begin{align}\n",
    "z_{1} = b_{1} + x\\cdot w_{1}\n",
    "\\end{align}\n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "z_{2} = b_{2} + x\\cdot w_{2}\n",
    "\\end{align}\n",
    "$$\n",
    "using four parameters: two intercepts and two slopes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we construct another linear model with the as inputs:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{y} := v = b_{3} + z_{1}\\cdot u_{1} + z_{2}\\cdot u_{2}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together:\n",
    "$$\n",
    "\\begin{align}\n",
    "v = b_{3} + z_{1}\\cdot u_{1} + z_{2}\\cdot u_{2} \\\\\n",
    "= b_{3} + (b_{1} + x\\cdot w_{1})\\cdot u_{1} + (b_{2} + x\\cdot w_{2})\\cdot u_{2} \\\\\n",
    "= (b_{3} + u_{1}\\cdot b_{1} + u_{2}\\cdot b_{2})+(w_{1}\\cdot u_{1} + w_{2}\\cdot u_{2})\\cdot x \\\\\n",
    "= (intercept) + (slope)\\cdot x.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is over-parametrized, with infinitely many ways to describe the same model. Essentially, still a linear model!\n",
    "<img src=\"./imgs/nn_2.png\" width=\"400\" height=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We capture non-linear relationships between and by replacing\n",
    "$$\n",
    "\\begin{align}\n",
    "v = b_{3} + z_{1}\\cdot u_{1} + z_{2}\\cdot u_{2}\n",
    "\\end{align}\n",
    "$$\n",
    "with\n",
    "$$\n",
    "\\begin{align}\n",
    "v = b_{3} + \\sigma(z_{1})\\cdot u_{1} + \\sigma(z_{2})\\cdot u_{2} \\\\\n",
    "= b_{3} + \\sigma(b_{1} + x\\cdot w_{1})\\cdot u_{1} + \\sigma(b_{2} + x\\cdot w_{2})\\cdot u_{2}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\sigma(\\cdot)$ is an activation function, a mapping from $\\mathbb{R}$ to $\\mathbb{R}$. Adding an activation function greatly increases the set of possible relations between $v$ and $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the rectified linear unit (ReLU) activation function:\n",
    "\\begin{equation}\n",
    "  D_{it} =\n",
    "    \\begin{cases}\n",
    "      x, & \\text{if x>0}\\\\\n",
    "      0, & \\text{otherwise.}\\\\\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "<img src=\"./imgs/nn_3.png\" width=\"400\" height=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 From the simple neural network to ANNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial Neural networks (ANNs):\n",
    "* a collection of neurons\n",
    "* organized into an ordered set of layers\n",
    "* directed connections pass signals between neurons in adjacent layers\n",
    "*to train:\n",
    "    * update parameters describing the connections by minimizing loss function over training data \n",
    "* to predict:\n",
    "    * pass $x$ to first layer, output of final layer is \\hat{y}.\n",
    "The network is dense or densely connected if each neuron in a layer receives an input from all the neurons present in the previous layer.\n",
    "</figure>\n",
    "<figure>\n",
    "<img src=\"./imgs/nn_4.png\" alt=\"autoencoder_schema\" style=\"width: 400px;\"/>\n",
    "<figcaption><center>This is a _feedforward_ neural network - no loops!<p></p></center></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 From the simple neural network to ANNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the neural nets terminology or language:\n",
    "* intercept called the bias\n",
    "* slopes called weights\n",
    "* $L + 1$ layers in total, with input layer 0 denoted as layer 0 and output layer as $L$\n",
    "* use $a$ (from activation) to denote the output of agiven neuron in a given layer\n",
    "</figure>\n",
    "<figure>\n",
    "<img src=\"./imgs/nn_5.png\" alt=\"autoencoder_schema\" style=\"width: 400px;\"/>\n",
    "<figcaption><center>A single layer ANN, also called perceptron or artificial neuron.\n",
    "<p></p></center></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Neural network architecture in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a neural network:\n",
    "* input travels through a **sequence** of layers, and gets transformed into the output\n",
    "* layers in-between the input layer and the output layer are called hidden layers\n",
    "* _tf.keras.layer.Dense_ object deploys a fully connected layer in the neural network\n",
    "\n",
    "This sequential layer structure is really at the core of the Keras libary. Tensorflow Sequential API is endowed will all the necessary tools for setting up neural networks. Keras and TensorFlow 2.0 provide you with three methods to implement your own neural network architectures:\n",
    "* Sequential API\n",
    "* Functional API\n",
    "* Model subclassing\n",
    "<img src=\"./imgs/nn_6.png\" width=\"400\" height=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "\n",
    "```python\n",
    "model.add(tf.keras.layers.Dense(units = 16,\n",
    "                                activation = 'sigmoid',\n",
    "                                input_shape = (784,)))  Sequential model\n",
    "```\n",
    "* **units = 16**: number of nodes in the given layer\n",
    "* **activation = 'sigmoid'**: this hidden layer uses the sigmoid activation function.\n",
    "* **input_shape = (784,)**:\n",
    "    * tells the first hidden layer how many input features there are\n",
    "    * only required for the first tf.keras.layers.Dense instantiation in a Sequential model\n",
    "    * differently from R, it must be specified as array and not as integer (even if one-dimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_random_seeds(seed)\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.keras.backend.set_session(session_conf)\n",
    "\n",
    "# instantiate model object\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network structure - adding first layer (Dense-type, fully connected)\n",
    "model.add(tf.keras.layers.Dense(units = 16,\n",
    "                                activation = 'sigmoid', \n",
    "                                input_shape = (784,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural networdk structure - adding output layer (Dense-type, fully connected)\n",
    "model.add(tf.keras.layers.Dense(units = 10, activation = 'softmax')) # activation function depends on the type of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(optimizer = 'RMSprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# close session (reproducibility)\n",
    "tf.compat.v1.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 12,730\n",
      "Trainable params: 12,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module ```from tensorflow.keras.utils import plot_model``` provides visualization tools for the neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model structure\n",
    "tf.keras.utils.plot_model(model=model, show_shapes=True, to_file='./imgs/model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that fit(.) tunes the model parameters (the weights and bias terms), we use fit() to start executing model training.\n",
    "\n",
    "```python\n",
    "model.fit(x = arr_vec_x_train, \n",
    "          y = output, \n",
    "          batch_size = 128, \n",
    "          epochs = 10, \n",
    "          validation_split = 0.2)\n",
    "```\n",
    "* **x = arr_vec_x_train**: wa train the images contained in arr_vec_x_train and their corresponding labels **y = output**\n",
    "* **batch_size = 128**: Parameter updates are calculated based on small subsets of the training data with batch_size elements\n",
    "* **epochs = 10**: An epoch is one iteration of the algorithm over the full dataset.\n",
    "* **validation_split = 0.2**:we use the last 20% ofour input training data as a hold-out validation set. We evaluate the loss on this validation set at the end of each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 1s 28us/sample - loss: 1.2724 - accuracy: 0.7501 - val_loss: 0.7536 - val_accuracy: 0.8697\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5972 - accuracy: 0.8779 - val_loss: 0.4489 - val_accuracy: 0.8971\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4143 - accuracy: 0.8976 - val_loss: 0.3529 - val_accuracy: 0.9095loss: 0.4149 - accuracy: 0.89\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.3453 - accuracy: 0.9096 - val_loss: 0.3108 - val_accuracy: 0.9154\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 1s 15us/sample - loss: 0.3089 - accuracy: 0.9155 - val_loss: 0.2862 - val_accuracy: 0.9212\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.2853 - accuracy: 0.9209 - val_loss: 0.2708 - val_accuracy: 0.9242\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.2678 - accuracy: 0.9238 - val_loss: 0.2583 - val_accuracy: 0.9283\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.2542 - accuracy: 0.9280 - val_loss: 0.2485 - val_accuracy: 0.9302\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 1s 15us/sample - loss: 0.2431 - accuracy: 0.9305 - val_loss: 0.2394 - val_accuracy: 0.9324\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.2337 - accuracy: 0.9328 - val_loss: 0.2333 - val_accuracy: 0.9329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cfd237e208>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(arr_vec_x_train, \n",
    "          output, \n",
    "          batch_size = 128, \n",
    "          epochs = 10, \n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate(.) calculates losses and metrics on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.23416787028312683, accuracy:0.9333000183105469\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "test_loss, test_accuracy = model.evaluate(arr_vec_x_test, test_output, verbose = 0)\n",
    "print(f'loss:{test_loss}, accuracy:{test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test reproducibility\n",
    "# loss:0.23416787028312683, accuracy:0.9333000183105469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "prediction = np.round(model.predict(arr_vec_x_test),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.   , 0.001, 0.002, 0.   , 0.   , 0.   , 0.996, 0.   ,\n",
       "       0.001], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0] # first row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to map the highest score to the referring category. Afterwards, we extract the mist-predicted categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction vs actual\n",
    "predicted_category = np.argmax(prediction, axis = 1)\n",
    "actual_category = np.argmax(test_output, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_category</th>\n",
       "      <th>actual_category</th>\n",
       "      <th>correct_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_category  actual_category  correct_classification\n",
       "0              7                7                    True\n",
       "1              2                2                    True\n",
       "2              1                1                    True\n",
       "3              0                0                    True\n",
       "4              4                4                    True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame({'pred_category':predicted_category,\n",
    "                        'actual_category':actual_category,\n",
    "                        'correct_classification':np.equal(predicted_category,actual_category)}); summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mis-predicted count\n",
    "(~summary.correct_classification).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test reproducibility\n",
    "# 666"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the mispredicted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's retrieve the index of mispredicted values from summary\n",
    "idx = summary[(~summary.correct_classification)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(vector_picture, wrong, actual_v, predited_v):\n",
    "    pixels = vector_picture.reshape((28,28))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.title(f'actual:{actual_category[wrong]}, predicted:{predicted_category[wrong]}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of mis-predicted values\n",
    "wrong = idx[623]\n",
    "ex = arr_vec_x_test[wrong]\n",
    "plot_img(ex, wrong, actual_category, predicted_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.996, 0.978, 0.986, ..., 0.956, 0.967, 0.995], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[np.arange(prediction.shape[0]), actual_category]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 Your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now design, compile and fit your own neural network for the MNIST dataset.\n",
    "\n",
    "As a form of paralellized model selection, all of us will play with different model parameters. This way we gain insight into which parameter values work well for this dataset.\n",
    "\n",
    "Base model: the neural network with a single hidden layer, as specified in the R script.\n",
    "\n",
    "Try some of the following ideas to improve the model:\n",
    "* add hidden layers: the number of nodes in subsequent layers should decrease\n",
    "* change batch size\n",
    "* change the activation function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1:** deploying a _tf.keras.layers.GaussianNoise_ between the 2 fully-connected hiddel layers causes a drop in the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:2.1349953987121584, accuracy:0.5503000020980835\n"
     ]
    }
   ],
   "source": [
    "reset_random_seeds(seed)\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.keras.backend.set_session(session_conf)\n",
    "\n",
    "# instantiate model object\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units = 16,\n",
    "                                activation = 'sigmoid', \n",
    "                                input_shape = (784,)))\n",
    "model.add(tf.keras.layers.GaussianNoise(stddev = 4)) # std = 4\n",
    "model.add(tf.keras.layers.Dense(units = 10, activation = 'softmax'))\n",
    "model.compile(optimizer = 'RMSprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(arr_vec_x_train, \n",
    "          output, \n",
    "          batch_size = 128, \n",
    "          epochs = 10, \n",
    "          validation_split = 0.2,\n",
    "          verbose = 0)\n",
    "\n",
    "tf.compat.v1.keras.backend.clear_session()\n",
    "\n",
    "# evaluate model\n",
    "test_loss, test_accuracy = model.evaluate(arr_vec_x_test, test_output, verbose = 0)\n",
    "print(f'loss:{test_loss}, accuracy:{test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test reproducibility\n",
    "# loss:2.1349953987121584, accuracy:0.5503000020980835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_category</th>\n",
       "      <th>actual_category</th>\n",
       "      <th>correct_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_category  actual_category  correct_classification\n",
       "0              7                7                    True\n",
       "1              1                2                   False\n",
       "2              1                1                    True\n",
       "3              0                0                    True\n",
       "4              9                4                   False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction vs actual\n",
    "prediction = np.round(model.predict(arr_vec_x_test),3)\n",
    "predicted_category = np.argmax(prediction, axis = 1)\n",
    "actual_category = np.argmax(test_output, axis = 1)\n",
    "summary = pd.DataFrame({'pred_category':predicted_category,\n",
    "                        'actual_category':actual_category,\n",
    "                        'correct_classification':np.equal(predicted_category,actual_category)}); summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4506"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of mis-predicted categories\n",
    "(~summary.correct_classification).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test reproducibility (tf.keras.layers.GaussianNoise(stddev = 4))\n",
    "# 4506"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6 Dealing with overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several methods proposed to reduce overfitting:\n",
    "* try different weight initializations\n",
    "* early stopping\n",
    "    *calculate validation performance after each epoch\n",
    "    *stop when this no longer improves\n",
    "* regularization (cfr. lasso and {glmnet}): e.g.\n",
    "    * $\\min\\limits_{w,b}\\mathcal{L}(w,b) + \\frac{\\lambda}{2}\\cdot||w||^{2}_{2}$\n",
    "* dropout\n",
    "    * randomly set activations to zero, with fixed $p$ \n",
    "    * probability both in forward propagation as well as backpropagation\n",
    "    * only in training, all nodes turned on during prediction.\n",
    "    \n",
    "Example code:\n",
    "```python\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units = 16,\n",
    "                                activation = 'sigmoid', \n",
    "                                input_shape = (784,),\n",
    "                                kernel_regularizer = tf.keras.regularizers.l1(0.01)))\n",
    "model.add(tf.keras.layers.Dense(units = 10, activation = 'softmax'))\n",
    "model.compile(optimizer = 'RMSprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
