{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claim frequency and severity regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now predict claim frequency and severity in the MTPL data with a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libs\n",
    "from IPython.display import display, Math, Latex\n",
    "import tensorflow as tf\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data using separator to correctly parse from .txt\n",
    "df = pd.read_csv(os.path.join(os.getcwd(),\"data\\PC_data.txt\"),  sep=r\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names to smaller case\n",
    "df.columns = map(str.lower, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nclaims</th>\n",
       "      <th>amount</th>\n",
       "      <th>avg</th>\n",
       "      <th>expo</th>\n",
       "      <th>coverage</th>\n",
       "      <th>fuel</th>\n",
       "      <th>use</th>\n",
       "      <th>fleet</th>\n",
       "      <th>sex</th>\n",
       "      <th>ageph</th>\n",
       "      <th>bm</th>\n",
       "      <th>agec</th>\n",
       "      <th>power</th>\n",
       "      <th>pc</th>\n",
       "      <th>town</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1618.001036</td>\n",
       "      <td>1618.001036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>TPL</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>private</td>\n",
       "      <td>N</td>\n",
       "      <td>male</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>77</td>\n",
       "      <td>1000</td>\n",
       "      <td>BRUSSEL</td>\n",
       "      <td>4.355223</td>\n",
       "      <td>50.845386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>PO</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>private</td>\n",
       "      <td>N</td>\n",
       "      <td>female</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>1000</td>\n",
       "      <td>BRUSSEL</td>\n",
       "      <td>4.355223</td>\n",
       "      <td>50.845386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>TPL</td>\n",
       "      <td>diesel</td>\n",
       "      <td>private</td>\n",
       "      <td>N</td>\n",
       "      <td>male</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>1000</td>\n",
       "      <td>BRUSSEL</td>\n",
       "      <td>4.355223</td>\n",
       "      <td>50.845386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>TPL</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>private</td>\n",
       "      <td>N</td>\n",
       "      <td>male</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>57</td>\n",
       "      <td>1000</td>\n",
       "      <td>BRUSSEL</td>\n",
       "      <td>4.355223</td>\n",
       "      <td>50.845386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>155.974606</td>\n",
       "      <td>155.974606</td>\n",
       "      <td>0.046575</td>\n",
       "      <td>TPL</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>private</td>\n",
       "      <td>N</td>\n",
       "      <td>female</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>1000</td>\n",
       "      <td>BRUSSEL</td>\n",
       "      <td>4.355223</td>\n",
       "      <td>50.845386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  nclaims       amount          avg      expo coverage      fuel  \\\n",
       "0   1        1  1618.001036  1618.001036  1.000000      TPL  gasoline   \n",
       "1   2        0     0.000000          NaN  1.000000       PO  gasoline   \n",
       "2   3        0     0.000000          NaN  1.000000      TPL    diesel   \n",
       "3   4        0     0.000000          NaN  1.000000      TPL  gasoline   \n",
       "4   5        1   155.974606   155.974606  0.046575      TPL  gasoline   \n",
       "\n",
       "       use fleet     sex  ageph  bm  agec  power    pc     town      long  \\\n",
       "0  private     N    male     50   5    12     77  1000  BRUSSEL  4.355223   \n",
       "1  private     N  female     64   5     3     66  1000  BRUSSEL  4.355223   \n",
       "2  private     N    male     60   0    10     70  1000  BRUSSEL  4.355223   \n",
       "3  private     N    male     77   0    15     57  1000  BRUSSEL  4.355223   \n",
       "4  private     N  female     28   9     7     70  1000  BRUSSEL  4.355223   \n",
       "\n",
       "         lat  \n",
       "0  50.845386  \n",
       "1  50.845386  \n",
       "2  50.845386  \n",
       "3  50.845386  \n",
       "4  50.845386  "
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename exp to expo\n",
    "df.rename(columns={'exp':'expo'}, inplace = True); df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:(122423, 18), test size:(40808, 18)\n"
     ]
    }
   ],
   "source": [
    "# train/test split using sklearn\n",
    "train, test = train_test_split(df, test_size=0.25); print(f'train size:{train.shape}, test size:{test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:(122423, 18)\n"
     ]
    }
   ],
   "source": [
    "# Reshuffling of the training observations\n",
    "train = train.sample(frac = 1); print(f'train size:{train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a model with only an intercept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize NN\n",
    "nn_freq_intercept = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add fully connected layer using exponential actiavation function\n",
    "nn_freq_intercept.add(tf.keras.layers.Dense(units = 1, activation = 'exponential', input_shape = (1,), use_bias = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choince of the optimizer and loglikelihood to maximize\n",
    "nn_freq_intercept.compile(optimizer = 'RMSprop', loss = 'poisson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q: how many parameters does this model have?\n",
    "nn_freq_intercept.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 1)                 1         \n",
      "=================================================================\n",
      "Total params: 1\n",
      "Trainable params: 1\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary of the structure of the neural netweork\n",
    "nn_freq_intercept.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of intercept vector: 122423, size of counts vector: 122423\n"
     ]
    }
   ],
   "source": [
    "# create vectors for the input and output\n",
    "intercept = np.ones(train.shape[0])\n",
    "counts = np.array(train['nclaims'])\n",
    "print(f'size of intercept vector: {intercept.shape[0]}, size of counts vector: {counts.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2512b5c05c8>"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the neural netword\n",
    "nn_freq_intercept.fit(intercept,\n",
    "                      counts,\n",
    "                      epochs = 30,\n",
    "                      batch_size = 1024,\n",
    "                      validation_split = 0,\n",
    "                      verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare the results of our neural network with the same model specified as a GLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>nclaims</td>     <th>  No. Observations:  </th>  <td>122423</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>122422</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -48318.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 05 Oct 2021</td> <th>  Deviance:          </th> <td>  68044.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>22:02:05</td>     <th>  Pearson chi2:      </th> <td>1.34e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>6</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -2.0765</td> <td>    0.008</td> <td> -257.251</td> <td> 0.000</td> <td>   -2.092</td> <td>   -2.061</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                nclaims   No. Observations:               122423\n",
       "Model:                            GLM   Df Residuals:                   122422\n",
       "Model Family:                 Poisson   Df Model:                            0\n",
       "Link Function:                    log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -48318.\n",
       "Date:                Tue, 05 Oct 2021   Deviance:                       68044.\n",
       "Time:                        22:02:05   Pearson chi2:                 1.34e+05\n",
       "No. Iterations:                     6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -2.0765      0.008   -257.251      0.000      -2.092      -2.061\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_freq_intercept = sm.formula.glm(\"nclaims ~ 1\", data=train, family=sm.families.Poisson()).fit(); glm_freq_intercept.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN weights:-2.0731935501098633, \n",
      "GLM coefficients:-2.0764970885376215\n"
     ]
    }
   ],
   "source": [
    "# comparing the estimated parameter (difference reflects a different optimization technique)\n",
    "print(f'NN weights:{nn_freq_intercept.get_weights()[0][0][0]}, \\nGLM coefficients:{glm_freq_intercept.params[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: adapt this code to replicate a binomial GLM with a logit link function. Add accuracy as a metric in your model.\n",
    "exercize_nn = tf.keras.models.Sequential()\n",
    "exercize_nn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid', input_shape = (1,), use_bias = False))\n",
    "exercize_nn.compile(optimizer = 'RMSprop', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2513cd93b08>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2: fit your neural network\n",
    "exercize_nn.fit(intercept,\n",
    "                      counts > 0,\n",
    "                      epochs = 40,\n",
    "                      batch_size = 1024,\n",
    "                      validation_split = 0,\n",
    "                      verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN weights:-2.063455104827881, \n",
      "GLM coefficients:-2.0671407011235106\n"
     ]
    }
   ],
   "source": [
    "# Q3: compare with GLM\n",
    "exercize_glm = sm.formula.glm(\"nclaims < 1 ~ 1\", # it must be fitted this way or 0/1 labels get switched\n",
    "                            data=train, \n",
    "                            family=sm.families.Binomial(sm.families.links.logit())).fit();\n",
    "    \n",
    "print(f'NN weights:{exercize_nn.get_weights()[0][0][0]}, \\nGLM coefficients:{exercize_glm.params[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercize_glm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11233183, 0.11233183, 0.11233183, ..., 0.11233183, 0.11233183,\n",
       "       0.11233183])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercize_glm.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11233])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3: compare prediction\n",
    "np.unique(np.round(exercize_glm.predict(),5)) # PERCHE' 1 - exercize_glm.predict()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1127], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.round(exercize_nn.predict(x = intercept),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF THE EXERCIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking exposure into account in a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classical GLM including exposure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>nclaims</td>     <th>  No. Observations:  </th>  <td>122423</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>122421</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -47577.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 05 Oct 2021</td> <th>  Deviance:          </th> <td>  66792.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>15:27:56</td>     <th>  Pearson chi2:      </th> <td>1.50e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>6</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -1.2396</td> <td>    0.026</td> <td>  -46.864</td> <td> 0.000</td> <td>   -1.291</td> <td>   -1.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ageph</th>     <td>   -0.0160</td> <td>    0.001</td> <td>  -27.930</td> <td> 0.000</td> <td>   -0.017</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                nclaims   No. Observations:               122423\n",
       "Model:                            GLM   Df Residuals:                   122421\n",
       "Model Family:                 Poisson   Df Model:                            1\n",
       "Link Function:                    log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -47577.\n",
       "Date:                Tue, 05 Oct 2021   Deviance:                       66792.\n",
       "Time:                        15:27:56   Pearson chi2:                 1.50e+05\n",
       "No. Iterations:                     6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -1.2396      0.026    -46.864      0.000      -1.291      -1.188\n",
       "ageph         -0.0160      0.001    -27.930      0.000      -0.017      -0.015\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_offset = sm.formula.glm(\"nclaims ~ ageph\", \n",
    "                            data=train, \n",
    "                            offset = np.log(train.expo),\n",
    "                            family=sm.families.Poisson()).fit(); \n",
    "glm_offset.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept   -1.239626\n",
       "ageph       -0.015975\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_offset.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classical GLM including weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>nclaims</td>     <th>  No. Observations:  </th>  <td>122423</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>122421</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -47577.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 05 Oct 2021</td> <th>  Deviance:          </th> <td>  66792.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>15:30:07</td>     <th>  Pearson chi2:      </th> <td>1.50e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>6</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -1.2396</td> <td>    0.026</td> <td>  -46.864</td> <td> 0.000</td> <td>   -1.291</td> <td>   -1.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ageph</th>     <td>   -0.0160</td> <td>    0.001</td> <td>  -27.930</td> <td> 0.000</td> <td>   -0.017</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                nclaims   No. Observations:               122423\n",
       "Model:                            GLM   Df Residuals:                   122421\n",
       "Model Family:                 Poisson   Df Model:                            1\n",
       "Link Function:                    log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -47577.\n",
       "Date:                Tue, 05 Oct 2021   Deviance:                       66792.\n",
       "Time:                        15:30:07   Pearson chi2:                 1.50e+05\n",
       "No. Iterations:                     6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -1.2396      0.026    -46.864      0.000      -1.291      -1.188\n",
       "ageph         -0.0160      0.001    -27.930      0.000      -0.017      -0.015\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_weights = sm.formula.glm(\"nclaims ~ ageph\", \n",
    "                             data=train, \n",
    "                             weights = train.expo, \n",
    "                             exposure = train.expo, \n",
    "                             family=sm.families.Poisson()).fit(); \n",
    "glm_weights.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept   -1.239626\n",
       "ageph       -0.015975\n",
       "dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_weights.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specification structure of the neural network remains the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network architecture specification\n",
    "nn_freq_exposure = tf.keras.models.Sequential()\n",
    "nn_freq_exposure.add(tf.keras.layers.Dense(units = 1, activation = 'exponential', input_shape = (1,), use_bias = False))\n",
    "nn_freq_exposure.compile(optimizer = 'RMSprop', loss = 'poisson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector with exposure values (pd.Series must be converted to pd.array due to compatibility reasons with fit() method)\n",
    "exposure = np.array(train['expo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2512e61f548>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide claim counts by exposure and use weights\n",
    "nn_freq_exposure.fit(x = intercept,\n",
    "                     y = counts/exposure,\n",
    "                     sample_weight = exposure,\n",
    "                     epochs = 20,\n",
    "                     batch_size = 1024,\n",
    "                     validation_split = 0,\n",
    "                     verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.7919232]], dtype=float32)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_freq_exposure.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN weights:-1.79192316532135, \n",
      "\n",
      "GLM_offset coefficients:Intercept   -1.239626\n",
      "ageph       -0.015975\n",
      "dtype: float64, \n",
      "\n",
      "GLM_weights coefficients:Intercept   -1.239626\n",
      "ageph       -0.015975\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# comparing the estimated parameter (difference reflects a different optimization technique)\n",
    "print(f'NN weights:{nn_freq_exposure.get_weights()[0][0][0]}, \\n\\nGLM_offset coefficients:{glm_offset.params}, \\n\\nGLM_weights coefficients:{glm_weights.params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we include exposure via an offset term?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector with ageph (pd.Series must be converted to pd.array due to compatibility reasons with fit() method)\n",
    "ageph = np.array(train['ageph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network architecture specification\n",
    "nn_freq_ageph = tf.keras.models.Sequential()\n",
    "nn_freq_ageph.add(tf.keras.layers.BatchNormalization(input_shape = (1,))) # layer_batch_normalization centers and scales the input features\n",
    "nn_freq_ageph.add(tf.keras.layers.Dense(units = 5, activation = 'tanh'))\n",
    "nn_freq_ageph.add(tf.keras.layers.Dense(units = 1, activation = 'exponential', use_bias = True)) # Notice how we set use_bias = TRUE for the intercept.\n",
    "nn_freq_ageph.compile(optimizer = 'RMSprop', loss = 'poisson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25134120608>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_freq_ageph.fit(ageph,\n",
    "                 counts/exposure,\n",
    "                 sample_weight = exposure,\n",
    "                 epochs = 20,\n",
    "                 batch_size = 1024,\n",
    "                 validation_split = 0,\n",
    "                 verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.58682483], dtype=float32),\n",
       " array([0.4486653], dtype=float32),\n",
       " array([46.986446], dtype=float32),\n",
       " array([219.16087], dtype=float32),\n",
       " array([[-0.41990626,  0.3513118 ,  0.2744854 ,  0.00437251,  0.65964603]],\n",
       "       dtype=float32),\n",
       " array([-0.41606426,  0.40605304, -0.3920835 ,  0.40150648,  0.46706387],\n",
       "       dtype=float32),\n",
       " array([[ 0.65044665],\n",
       "        [-0.81724334],\n",
       "        [ 1.0437535 ],\n",
       "        [-0.48028782],\n",
       "        [-0.6920566 ]], dtype=float32),\n",
       " array([-0.38707754], dtype=float32)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_freq_ageph.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying GAM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.gam.api import GLMGam, BSplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_spline = train['ageph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BSplines(x_spline, df=[10, 10], degree=[3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>nclaims</td>     <th>  No. Observations:  </th>  <td>122423</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                <td>GLMGam</td>      <th>  Df Residuals:      </th>  <td>122413</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>         <td>Poisson</td>     <th>  Df Model:          </th> <td>    9.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>PIRLS</td>      <th>  Log-Likelihood:    </th> <td> -47500.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 05 Oct 2021</td> <th>  Deviance:          </th> <td>  66638.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:40:40</td>     <th>  Pearson chi2:      </th> <td>1.48e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>7</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -1.0596</td> <td>    0.154</td> <td>   -6.892</td> <td> 0.000</td> <td>   -1.361</td> <td>   -0.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ageph_s0</th>  <td>   -0.2392</td> <td>    0.235</td> <td>   -1.018</td> <td> 0.308</td> <td>   -0.700</td> <td>    0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ageph_s1</th>  <td>   -0.6825</td> <td>    0.135</td> <td>   -5.074</td> <td> 0.000</td> <td>   -0.946</td> <td>   -0.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ageph_s2</th>  <td>   -0.9138</td> <td>    0.173</td> <td>   -5.273</td> <td> 0.000</td> <td>   -1.253</td> <td>   -0.574</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ageph_s3</th>  <td>   -0.8834</td> <td>    0.153</td> <td>   -5.763</td> <td> 0.000</td> <td>   -1.184</td> <td>   -0.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ageph_s4</th>  <td>   -0.9453</td> <td>    0.164</td> <td>   -5.778</td> <td> 0.000</td> <td>   -1.266</td> <td>   -0.625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ageph_s5</th>  <td>   -1.0862</td> <td>    0.160</td> <td>   -6.783</td> <td> 0.000</td> <td>   -1.400</td> <td>   -0.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ageph_s6</th>  <td>   -1.4764</td> <td>    0.196</td> <td>   -7.543</td> <td> 0.000</td> <td>   -1.860</td> <td>   -1.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ageph_s7</th>  <td>   -1.0548</td> <td>    0.278</td> <td>   -3.794</td> <td> 0.000</td> <td>   -1.600</td> <td>   -0.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ageph_s8</th>  <td>   -0.6534</td> <td>    0.501</td> <td>   -1.305</td> <td> 0.192</td> <td>   -1.635</td> <td>    0.328</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                nclaims   No. Observations:               122423\n",
       "Model:                         GLMGam   Df Residuals:                   122413\n",
       "Model Family:                 Poisson   Df Model:                         9.00\n",
       "Link Function:                    log   Scale:                          1.0000\n",
       "Method:                         PIRLS   Log-Likelihood:                -47500.\n",
       "Date:                Tue, 05 Oct 2021   Deviance:                       66638.\n",
       "Time:                        16:40:40   Pearson chi2:                 1.48e+05\n",
       "No. Iterations:                     7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -1.0596      0.154     -6.892      0.000      -1.361      -0.758\n",
       "ageph_s0      -0.2392      0.235     -1.018      0.308      -0.700       0.221\n",
       "ageph_s1      -0.6825      0.135     -5.074      0.000      -0.946      -0.419\n",
       "ageph_s2      -0.9138      0.173     -5.273      0.000      -1.253      -0.574\n",
       "ageph_s3      -0.8834      0.153     -5.763      0.000      -1.184      -0.583\n",
       "ageph_s4      -0.9453      0.164     -5.778      0.000      -1.266      -0.625\n",
       "ageph_s5      -1.0862      0.160     -6.783      0.000      -1.400      -0.772\n",
       "ageph_s6      -1.4764      0.196     -7.543      0.000      -1.860      -1.093\n",
       "ageph_s7      -1.0548      0.278     -3.794      0.000      -1.600      -0.510\n",
       "ageph_s8      -0.6534      0.501     -1.305      0.192      -1.635       0.328\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gam_bs = GLMGam.from_formula('nclaims ~ 1', \n",
    "                             data=train, \n",
    "                             smoother=bs, \n",
    "                             family=sm.families.Poisson(sm.families.links.log()),\n",
    "                             offset = np.log(train.expo)).fit();\n",
    "gam_bs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153372    0.166440\n",
       "144123    0.288133\n",
       "70929     0.137357\n",
       "6673      0.141733\n",
       "151603    0.141414\n",
       "            ...   \n",
       "68863     0.125252\n",
       "25199     0.122734\n",
       "155674    0.145292\n",
       "91343     0.009728\n",
       "75848     0.053720\n",
       "Length: 122423, dtype: float64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gam_bs.fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.166440\n",
       "1         0.288133\n",
       "2         0.137357\n",
       "3         0.141733\n",
       "4         0.141414\n",
       "            ...   \n",
       "122418    0.125252\n",
       "122419    0.135751\n",
       "122420    0.145292\n",
       "122421    0.098634\n",
       "122422    0.129854\n",
       "Length: 122423, dtype: float64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gam_bs.predict(exog = pd.DataFrame(np.ones(train.shape[0])),  exog_smooth = np.array(train['ageph']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.cast(np.array(range(18,96)), tf.float32)\n",
    "nn_pred = nn_freq_ageph.predict(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ageph':np.array(range(18,96)),\n",
    "                  'inter':np.ones(len(list(range(18,96))), dtype = int)})\n",
    "gam_pred = gam_bs.predict(exog = pd.DataFrame(np.ones(df.shape[0])),  exog_smooth = np.array(df['ageph']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array(range(18,96))\n",
    "plt.plot(x, gam_pred, label = \"GAM\")\n",
    "plt.plot(x, nn_pred, label = \"NN\")\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('fitted_effect')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a skip connection in a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A skip connection allows us to guide the neural net in the right direction and to model adjustments on top of the base predictions, for example obtained via a GLM or GAM. In the actuarial lingo this is called a Combined Actuarial Neural Network (CANN). We are now using Tensorflow Functional API instead of Sequential API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_skip = tf.keras.layers.Input(shape = (1,), name = 'skip')\n",
    "input_nn = tf.keras.layers.Input(shape = (1,), name = 'nn')\n",
    "norm_nn = tf.keras.layers.BatchNormalization()(input_nn)\n",
    "dense_1 = tf.keras.layers.Dense(units = 5, activation = 'tanh')(norm_nn)\n",
    "network = tf.keras.layers.Dense(units = 1, activation = 'linear')(dense_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "interm = tf.keras.layers.Add()([network, input_skip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.keras.layers.Dense(units = 1, \n",
    "                               activation = 'exponential', \n",
    "                               trainable = True, \n",
    "                               name = 'output',\n",
    "                              )(interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "cann = tf.keras.models.Model(inputs = [input_nn, input_skip], outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "cann.compile(optimizer = 'RMSprop', loss = 'poisson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34660200830959664"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(gam_bs.predict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153372   -1.793120\n",
       "144123   -1.244332\n",
       "70929    -1.985173\n",
       "6673     -1.953810\n",
       "151603   -1.956066\n",
       "            ...   \n",
       "68863    -2.077426\n",
       "25199    -2.198542\n",
       "155674   -1.929009\n",
       "91343    -6.949095\n",
       "75848    -3.806580\n",
       "Name: expo, Length: 122423, dtype: float64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gam_expo = np.log(gam_bs.predict()) + np.log(train['expo']); gam_expo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "cann_input = [np.array(train['ageph']), np.array(gam_expo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 122423 samples\n",
      "Epoch 1/20\n",
      "122423/122423 [==============================] - 1s 6us/sample - loss: 0.4217\n",
      "Epoch 2/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3969\n",
      "Epoch 3/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3948\n",
      "Epoch 4/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3930\n",
      "Epoch 5/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3913\n",
      "Epoch 6/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3898\n",
      "Epoch 7/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3884\n",
      "Epoch 8/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3872\n",
      "Epoch 9/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3861\n",
      "Epoch 10/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3852\n",
      "Epoch 11/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3844\n",
      "Epoch 12/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3835\n",
      "Epoch 13/20\n",
      "122423/122423 [==============================] - ETA: 0s - loss: 0.383 - 0s 1us/sample - loss: 0.3828\n",
      "Epoch 14/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3822\n",
      "Epoch 15/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3817\n",
      "Epoch 16/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3812\n",
      "Epoch 17/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3808\n",
      "Epoch 18/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3804\n",
      "Epoch 19/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3801\n",
      "Epoch 20/20\n",
      "122423/122423 [==============================] - 0s 1us/sample - loss: 0.3798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2513dba4bc8>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cann.fit(cann_input,\n",
    "         counts,\n",
    "         epochs = 20,\n",
    "         batch_size = 1024,\n",
    "         validation_split = 0,\n",
    "         verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ageph</th>\n",
       "      <th>skip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ageph  skip\n",
       "0     18   0.0\n",
       "1     19   0.0\n",
       "2     20   0.0\n",
       "3     21   0.0\n",
       "4     22   0.0"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test output\n",
    "df = pd.DataFrame({'ageph':np.array(range(18,96)),\n",
    "                   'skip':np.zeros(len(range(18,96)))}); df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ageph</th>\n",
       "      <th>skip</th>\n",
       "      <th>cann_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.495967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ageph  skip  cann_pred\n",
       "0     18   0.0   0.517595\n",
       "1     19   0.0   0.512163\n",
       "2     20   0.0   0.506744\n",
       "3     21   0.0   0.501343\n",
       "4     22   0.0   0.495967"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cann_pred'] = cann.predict([tf.cast(df.ageph, dtype=tf.float32),tf.cast(df.skip, dtype=tf.float32)]); df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cann_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\dev_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2898\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cann_pred'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-383-d6ea08f2eabd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ageph'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cann_pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"GAM\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cann_pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"NN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fitted_effect'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2904\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2906\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2907\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2898\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2900\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2902\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cann_pred'"
     ]
    }
   ],
   "source": [
    "x = df['ageph']\n",
    "plt.plot(x, df['cann_pred'], label = \"GAM\")\n",
    "plt.plot(x, df['cann_pred'], label = \"NN\")\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('fitted_effect')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = gam_bs.predict(exog = pd.DataFrame(np.array(range(18,96))),  exog_smooth = np.array(range(18,96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ageph</th>\n",
       "      <th>skip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>-1.059578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>-1.120147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>-1.181903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>-1.244332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>-1.306924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ageph      skip\n",
       "0     18 -1.059578\n",
       "1     19 -1.120147\n",
       "2     20 -1.181903\n",
       "3     21 -1.244332\n",
       "4     22 -1.306924"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test output\n",
    "df = pd.DataFrame({'ageph':np.array(range(18,96)),\n",
    "                   'skip':np.log(a)}); df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ageph</th>\n",
       "      <th>skip</th>\n",
       "      <th>cann_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>-1.059578</td>\n",
       "      <td>0.293769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>-1.120147</td>\n",
       "      <td>0.281426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>-1.181903</td>\n",
       "      <td>0.269406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>-1.244332</td>\n",
       "      <td>0.257787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>-1.306924</td>\n",
       "      <td>0.246631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ageph      skip  cann_pred\n",
       "0     18 -1.059578   0.293769\n",
       "1     19 -1.120147   0.281426\n",
       "2     20 -1.181903   0.269406\n",
       "3     21 -1.244332   0.257787\n",
       "4     22 -1.306924   0.246631"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cann_pred'] = cann.predict([tf.cast(df.ageph, dtype=tf.float32),tf.cast(df.skip, dtype=tf.float32)]); df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df['ageph']\n",
    "plt.plot(x, np.exp(df['skip']), label = \"GAM\")\n",
    "plt.plot(x, df['cann_pred'], label = \"NN\")\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('fitted_effect')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claim severity modeling with neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nclaims</th>\n",
       "      <th>amount</th>\n",
       "      <th>avg</th>\n",
       "      <th>expo</th>\n",
       "      <th>coverage</th>\n",
       "      <th>fuel</th>\n",
       "      <th>use</th>\n",
       "      <th>fleet</th>\n",
       "      <th>sex</th>\n",
       "      <th>ageph</th>\n",
       "      <th>bm</th>\n",
       "      <th>agec</th>\n",
       "      <th>power</th>\n",
       "      <th>pc</th>\n",
       "      <th>town</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42875</th>\n",
       "      <td>42876</td>\n",
       "      <td>1</td>\n",
       "      <td>297.521808</td>\n",
       "      <td>297.521808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TPL</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>private</td>\n",
       "      <td>N</td>\n",
       "      <td>female</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>66</td>\n",
       "      <td>2970</td>\n",
       "      <td>SCHILDE</td>\n",
       "      <td>4.569863</td>\n",
       "      <td>51.256762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78032</th>\n",
       "      <td>78033</td>\n",
       "      <td>1</td>\n",
       "      <td>635.995627</td>\n",
       "      <td>635.995627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PO</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>work</td>\n",
       "      <td>N</td>\n",
       "      <td>female</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>4850</td>\n",
       "      <td>PLOMBIER</td>\n",
       "      <td>5.951618</td>\n",
       "      <td>50.714810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78766</th>\n",
       "      <td>78767</td>\n",
       "      <td>1</td>\n",
       "      <td>130.788624</td>\n",
       "      <td>130.788624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PO</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>private</td>\n",
       "      <td>N</td>\n",
       "      <td>male</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>4900</td>\n",
       "      <td>SPA</td>\n",
       "      <td>5.855097</td>\n",
       "      <td>50.472596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95081</th>\n",
       "      <td>95082</td>\n",
       "      <td>2</td>\n",
       "      <td>193.877526</td>\n",
       "      <td>96.938763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TPL</td>\n",
       "      <td>diesel</td>\n",
       "      <td>private</td>\n",
       "      <td>N</td>\n",
       "      <td>female</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>6150</td>\n",
       "      <td>ANDERLUE</td>\n",
       "      <td>4.253717</td>\n",
       "      <td>50.404104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5922</th>\n",
       "      <td>5923</td>\n",
       "      <td>1</td>\n",
       "      <td>500.918446</td>\n",
       "      <td>500.918446</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PO</td>\n",
       "      <td>diesel</td>\n",
       "      <td>private</td>\n",
       "      <td>N</td>\n",
       "      <td>male</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>1090</td>\n",
       "      <td>JETTE</td>\n",
       "      <td>4.309525</td>\n",
       "      <td>50.882140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  nclaims      amount         avg  expo coverage      fuel  \\\n",
       "42875  42876        1  297.521808  297.521808   1.0      TPL  gasoline   \n",
       "78032  78033        1  635.995627  635.995627   1.0       PO  gasoline   \n",
       "78766  78767        1  130.788624  130.788624   1.0       PO  gasoline   \n",
       "95081  95082        2  193.877526   96.938763   1.0      TPL    diesel   \n",
       "5922    5923        1  500.918446  500.918446   1.0       PO    diesel   \n",
       "\n",
       "           use fleet     sex  ageph  bm  agec  power    pc      town  \\\n",
       "42875  private     N  female     48   5    10     66  2970   SCHILDE   \n",
       "78032     work     N  female     31   0     7     39  4850  PLOMBIER   \n",
       "78766  private     N    male     52   1     4     85  4900       SPA   \n",
       "95081  private     N  female     44   2     8     53  6150  ANDERLUE   \n",
       "5922   private     N    male     30   0     5     66  1090     JETTE   \n",
       "\n",
       "           long        lat  \n",
       "42875  4.569863  51.256762  \n",
       "78032  5.951618  50.714810  \n",
       "78766  5.855097  50.472596  \n",
       "95081  4.253717  50.404104  \n",
       "5922   4.309525  50.882140  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims = train[train.nclaims > 0]; df_claims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13752, 18)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's model the log severity with a MSE loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13752 samples\n",
      "Epoch 1/100\n",
      "13752/13752 [==============================] - 0s 24us/sample - loss: 23.3766\n",
      "Epoch 2/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 22.3916\n",
      "Epoch 3/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 21.4344\n",
      "Epoch 4/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 20.5005\n",
      "Epoch 5/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 19.5921\n",
      "Epoch 6/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 18.7036\n",
      "Epoch 7/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 17.84100s - loss: 18.04\n",
      "Epoch 8/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 16.9988\n",
      "Epoch 9/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 16.1815\n",
      "Epoch 10/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 15.3881\n",
      "Epoch 11/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 14.6200\n",
      "Epoch 12/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 13.8722\n",
      "Epoch 13/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 13.1468\n",
      "Epoch 14/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 12.4462\n",
      "Epoch 15/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 11.7697\n",
      "Epoch 16/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 11.1153\n",
      "Epoch 17/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 10.4824\n",
      "Epoch 18/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 9.8751\n",
      "Epoch 19/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 9.2908\n",
      "Epoch 20/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 8.7309\n",
      "Epoch 21/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 8.1918\n",
      "Epoch 22/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 7.6766 0s - loss: 7.76\n",
      "Epoch 23/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 7.1846\n",
      "Epoch 24/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 6.7164\n",
      "Epoch 25/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 6.2726 0s - loss: 6.42\n",
      "Epoch 26/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 5.8514\n",
      "Epoch 27/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 5.4515\n",
      "Epoch 28/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 5.0774\n",
      "Epoch 29/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 4.7248\n",
      "Epoch 30/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 4.3947\n",
      "Epoch 31/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 4.0891\n",
      "Epoch 32/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 3.8061\n",
      "Epoch 33/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 3.5469\n",
      "Epoch 34/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 3.3106\n",
      "Epoch 35/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 3.0968\n",
      "Epoch 36/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.9085\n",
      "Epoch 37/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.7402\n",
      "Epoch 38/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.5965\n",
      "Epoch 39/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.4757\n",
      "Epoch 40/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.3756\n",
      "Epoch 41/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.2996\n",
      "Epoch 42/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.2466\n",
      "Epoch 43/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.2125\n",
      "Epoch 44/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1958\n",
      "Epoch 45/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1912\n",
      "Epoch 46/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1903\n",
      "Epoch 47/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1901\n",
      "Epoch 48/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 49/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 50/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 51/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 52/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 53/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 54/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 55/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 56/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 57/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 58/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 59/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 60/100\n",
      "13752/13752 [==============================] - 0s 9us/sample - loss: 2.1900\n",
      "Epoch 61/100\n",
      "13752/13752 [==============================] - 0s 9us/sample - loss: 2.1900\n",
      "Epoch 62/100\n",
      "13752/13752 [==============================] - 0s 10us/sample - loss: 2.1900\n",
      "Epoch 63/100\n",
      "13752/13752 [==============================] - 0s 9us/sample - loss: 2.1900\n",
      "Epoch 64/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 65/100\n",
      "13752/13752 [==============================] - 0s 6us/sample - loss: 2.1900\n",
      "Epoch 66/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 67/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 68/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 69/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 70/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 71/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 72/100\n",
      "13752/13752 [==============================] - 0s 9us/sample - loss: 2.1900\n",
      "Epoch 73/100\n",
      "13752/13752 [==============================] - 0s 10us/sample - loss: 2.1900\n",
      "Epoch 74/100\n",
      "13752/13752 [==============================] - 0s 9us/sample - loss: 2.1900\n",
      "Epoch 75/100\n",
      "13752/13752 [==============================] - 0s 9us/sample - loss: 2.1900\n",
      "Epoch 76/100\n",
      "13752/13752 [==============================] - 0s 6us/sample - loss: 2.1900\n",
      "Epoch 77/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 78/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 79/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 80/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 81/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 82/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 83/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 84/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1899\n",
      "Epoch 85/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 86/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 87/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1899\n",
      "Epoch 88/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 89/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 90/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 91/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 93/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 94/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 95/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 96/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900 0s - loss: 2.185\n",
      "Epoch 97/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 98/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 2.1900\n",
      "Epoch 99/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n",
      "Epoch 100/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25145090688>"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_sev_log = tf.keras.models.Sequential()\n",
    "nn_sev_log.add(tf.keras.layers.Dense(units = 1, activation = 'linear', input_shape = (1,), use_bias = False))\n",
    "nn_sev_log.compile(optimizer = 'RMSprop', loss = 'mse')\n",
    "nn_sev_log.fit(x = np.array(np.ones(df_claims.shape[0])),\n",
    "              y = np.log(np.array(df_claims['avg'])),\n",
    "              epochs = 100,\n",
    "              batch_size = 128,\n",
    "              validation_split = 0,\n",
    "              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.69548753, 6.45519169, 4.87358246, ..., 7.26289458, 5.04203523,\n",
       "       4.50377059])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(np.array(df_claims['avg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 13749, 13750, 13751])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(range(df_claims.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453.82257080078125"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float(np.exp(nn_sev_log.predict(tf.cast([1], dtype = tf.float32))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.375200e+04\n",
       "mean     1.640646e+03\n",
       "std      1.866569e+04\n",
       "min      4.957870e-02\n",
       "25%      1.427619e+02\n",
       "50%      5.286391e+02\n",
       "75%      1.426379e+03\n",
       "max      1.989568e+06\n",
       "Name: avg, dtype: float64"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims['avg'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_gamma(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, dtype = tf.float32)\n",
    "    y_pred = tf.cast(y_pred, dtype = tf.float32)\n",
    "    return ((y_true - y_pred) / y_pred) - tf.math.log(y_true / y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13752 samples\n",
      "Epoch 1/100\n",
      "13752/13752 [==============================] - 0s 24us/sample - loss: 381.4913\n",
      "Epoch 2/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 348.6231\n",
      "Epoch 3/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 319.9109\n",
      "Epoch 4/100\n",
      "13752/13752 [==============================] - 0s 9us/sample - loss: 292.3375\n",
      "Epoch 5/100\n",
      "13752/13752 [==============================] - 0s 10us/sample - loss: 270.2446\n",
      "Epoch 6/100\n",
      "13752/13752 [==============================] - 0s 6us/sample - loss: 248.3748\n",
      "Epoch 7/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 225.5478\n",
      "Epoch 8/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 208.6724\n",
      "Epoch 9/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 191.1977\n",
      "Epoch 10/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 172.7751\n",
      "Epoch 11/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 159.3172\n",
      "Epoch 12/100\n",
      "13752/13752 [==============================] - ETA: 0s - loss: 153.571 - 0s 7us/sample - loss: 145.8676\n",
      "Epoch 13/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 133.9710\n",
      "Epoch 14/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 121.4352\n",
      "Epoch 15/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 112.0008\n",
      "Epoch 16/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 102.0618\n",
      "Epoch 17/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 93.5948\n",
      "Epoch 18/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 85.6061\n",
      "Epoch 19/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 78.2078\n",
      "Epoch 20/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 71.4569\n",
      "Epoch 21/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 65.5685\n",
      "Epoch 22/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 60.0418\n",
      "Epoch 23/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 54.2725\n",
      "Epoch 24/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 49.4944\n",
      "Epoch 25/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 45.3451\n",
      "Epoch 26/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 41.1242\n",
      "Epoch 27/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 37.3520\n",
      "Epoch 28/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 34.2682\n",
      "Epoch 29/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 31.2778\n",
      "Epoch 30/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 28.6552\n",
      "Epoch 31/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 26.1533\n",
      "Epoch 32/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 23.6981\n",
      "Epoch 33/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 21.5840\n",
      "Epoch 34/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 19.7440\n",
      "Epoch 35/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 17.9639\n",
      "Epoch 36/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 16.2902\n",
      "Epoch 37/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 14.9960\n",
      "Epoch 38/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 13.5698\n",
      "Epoch 39/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 12.18410s - loss: 11.\n",
      "Epoch 40/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 11.0660\n",
      "Epoch 41/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 10.2185\n",
      "Epoch 42/100\n",
      "13752/13752 [==============================] - 0s 10us/sample - loss: 9.1353\n",
      "Epoch 43/100\n",
      "13752/13752 [==============================] - 0s 9us/sample - loss: 8.3753\n",
      "Epoch 44/100\n",
      "13752/13752 [==============================] - 0s 9us/sample - loss: 7.5759\n",
      "Epoch 45/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 6.8545\n",
      "Epoch 46/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 6.3233\n",
      "Epoch 47/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 5.7186\n",
      "Epoch 48/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 5.2332\n",
      "Epoch 49/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 4.7814\n",
      "Epoch 50/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 4.3638\n",
      "Epoch 51/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 3.9846\n",
      "Epoch 52/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 3.6667\n",
      "Epoch 53/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 3.3444\n",
      "Epoch 54/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 3.0982\n",
      "Epoch 55/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.8524\n",
      "Epoch 56/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.6121\n",
      "Epoch 57/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.4385\n",
      "Epoch 58/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.2653\n",
      "Epoch 59/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 2.1177\n",
      "Epoch 60/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.9972\n",
      "Epoch 61/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.8913\n",
      "Epoch 62/100\n",
      "13752/13752 [==============================] - 0s 9us/sample - loss: 1.7879\n",
      "Epoch 63/100\n",
      "13752/13752 [==============================] - 0s 12us/sample - loss: 1.7043\n",
      "Epoch 64/100\n",
      "13752/13752 [==============================] - 0s 19us/sample - loss: 1.6235\n",
      "Epoch 65/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 1.5507\n",
      "Epoch 66/100\n",
      "13752/13752 [==============================] - 0s 9us/sample - loss: 1.4975\n",
      "Epoch 67/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 1.4605\n",
      "Epoch 68/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.4242\n",
      "Epoch 69/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.3943\n",
      "Epoch 70/100\n",
      "13752/13752 [==============================] - 0s 9us/sample - loss: 1.3776\n",
      "Epoch 71/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.3586\n",
      "Epoch 72/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.3423\n",
      "Epoch 73/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.3306\n",
      "Epoch 74/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.3219\n",
      "Epoch 75/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.3152\n",
      "Epoch 76/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.3109\n",
      "Epoch 77/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.3066\n",
      "Epoch 78/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.3037\n",
      "Epoch 79/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.3014\n",
      "Epoch 80/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2999\n",
      "Epoch 81/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2981\n",
      "Epoch 82/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2966\n",
      "Epoch 83/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2955\n",
      "Epoch 84/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2953\n",
      "Epoch 85/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2941\n",
      "Epoch 86/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2943\n",
      "Epoch 87/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2935\n",
      "Epoch 88/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 1.2933\n",
      "Epoch 89/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 1.2935\n",
      "Epoch 90/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2930\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2924\n",
      "Epoch 92/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2928\n",
      "Epoch 93/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2923\n",
      "Epoch 94/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2922 0s - loss: 1.308\n",
      "Epoch 95/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2919\n",
      "Epoch 96/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 1.2915\n",
      "Epoch 97/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2920\n",
      "Epoch 98/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2917\n",
      "Epoch 99/100\n",
      "13752/13752 [==============================] - 0s 7us/sample - loss: 1.2926 0s - loss: 1.420\n",
      "Epoch 100/100\n",
      "13752/13752 [==============================] - 0s 8us/sample - loss: 1.2925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25145688548>"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_sev_gamma = tf.keras.models.Sequential()\n",
    "nn_sev_gamma.add(tf.keras.layers.Dense(units = 1, activation = 'exponential', input_shape = (1,), use_bias = False))\n",
    "nn_sev_gamma.compile(optimizer = 'RMSprop', loss = k_gamma)\n",
    "nn_sev_gamma.fit(x = np.ones(df_claims.shape[0]),\n",
    "                 y = np.array(df_claims['avg']),\n",
    "                 epochs = 100,\n",
    "                 batch_size = 128,\n",
    "                 validation_split = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1469.9119873046875"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float(nn_sev_gamma.predict(tf.cast([1], dtype = tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1158.3359115397923"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df_claims[df_claims['avg'] < 30000]['avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
